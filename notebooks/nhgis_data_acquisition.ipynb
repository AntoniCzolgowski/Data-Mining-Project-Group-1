{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHGIS County-Level Demographic Data Acquisition\n",
    "## Swing State Election Analysis — CSCI 5502 Data Mining\n",
    "\n",
    "**Purpose:** Programmatically acquire county-level demographic and socio-economic data from IPUMS NHGIS via their API for three swing states (Pennsylvania, Michigan, North Carolina) aligned with Presidential election years (2016, 2020, 2024).\n",
    "\n",
    "**Data Source:** American Community Survey (ACS) 5-Year Estimates via [IPUMS NHGIS](https://www.nhgis.org/)  \n",
    "**API Docs:** [IPUMS Developer Portal](https://developer.ipums.org/docs/v2/apiprogram/apis/nhgis/)  \n",
    "**Python Library:** [`ipumspy`](https://ipumspy.readthedocs.io/en/latest/)\n",
    "\n",
    "---\n",
    "\n",
    "### How NHGIS API Works (Key Concepts)\n",
    "\n",
    "NHGIS does **not** provide a live query API. Instead, it uses an **extract system**:\n",
    "\n",
    "1. **Define** an extract request (which datasets, tables, geographic levels, extents)\n",
    "2. **Submit** the request to IPUMS servers for background processing\n",
    "3. **Wait** for processing to complete (typically 30 seconds–5 minutes)\n",
    "4. **Download** the resulting ZIP file containing CSV data + codebook\n",
    "5. **Read** the CSV into pandas for analysis\n",
    "\n",
    "### Dataset Naming Convention\n",
    "\n",
    "NHGIS organizes ACS data into datasets named by year range and variant:\n",
    "\n",
    "| Election Year | ACS 5-Year Period | NHGIS Dataset Name | Coverage |\n",
    "|---|---|---|---|\n",
    "| **2016** | 2012–2016 | `2012_2016_ACS5a` | Block Groups & Larger (incl. County) |\n",
    "| **2020** | 2016–2020 | `2016_2020_ACS5a` | Block Groups & Larger (incl. County) |\n",
    "| **2024** | 2020–2024 | `2020_2024_ACS5a` | Block Groups & Larger (incl. County) |\n",
    "\n",
    "The `a` suffix means the dataset includes tables available at the block group level and above.  \n",
    "The `b` suffix includes additional detailed tables available only at tract level and above.  \n",
    "We use `a` for most tables; we add `b` variants for specific detailed tables not in `a`.\n",
    "\n",
    "### Geographic Extent Codes (State FIPS + \"0\")\n",
    "\n",
    "| State | FIPS Code | NHGIS Extent Code |\n",
    "|---|---|---|\n",
    "| Pennsylvania | 42 | `420` |\n",
    "| Michigan | 26 | `260` |\n",
    "| North Carolina | 37 | `370` |\n",
    "\n",
    "### ACS Data Tables Selected\n",
    "\n",
    "These are the standard Census Bureau table codes, used identically in NHGIS:\n",
    "\n",
    "| Table Code | Description | Key Variables |\n",
    "|---|---|---|\n",
    "| **B01003** | Total Population | Total pop count |\n",
    "| **B01002** | Median Age by Sex | Median age |\n",
    "| **B02001** | Race | White, Black, Asian, etc. |\n",
    "| **B03002** | Hispanic/Latino Origin by Race | Hispanic breakdown |\n",
    "| **B15003** | Educational Attainment (25+) | HS, Bachelor's, Graduate |\n",
    "| **B19013** | Median Household Income | Dollar amount |\n",
    "| **B19001** | Household Income (brackets) | Income distribution |\n",
    "| **B17001** | Poverty Status | Below poverty line |\n",
    "| **B23025** | Employment Status | Unemployed, labor force |\n",
    "| **B25077** | Median Home Value | Dollar amount |\n",
    "| **B25003** | Tenure (Own vs. Rent) | Owner-occupied, Renter |\n",
    "| **B25064** | Median Gross Rent | Dollar amount |\n",
    "| **B08301** | Means of Transportation to Work | Car, transit, WFH |\n",
    "| **B11001** | Household Type | Family, nonfamily |\n",
    "\n",
    "> **Note on B-table availability:** Most B-tables are in `ACS5a`. Some detailed tables (B15003 has 25 categories) are only in `ACS5b`. We'll verify availability via metadata queries.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "# !pip install ipumspy pandas python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from ipumspy import (\n",
    "    IpumsApiClient,\n",
    "    AggregateDataExtract,\n",
    "    NhgisDataset,\n",
    "    NhgisDatasetMetadata,\n",
    "    NhgisDataTableMetadata,\n",
    "    save_extract_as_json,\n",
    "    define_extract_from_json,\n",
    ")\n",
    "\n",
    "# Load .env from repo root (walks up from notebook location)\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Imports successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API client initialized (key: 59cba10d...)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# API KEY SETUP\n",
    "# ============================================================\n",
    "# \n",
    "# Setup (one-time):\n",
    "#   1. Register at https://www.nhgis.org/\n",
    "#   2. Get API key at https://account.ipums.org/api_keys\n",
    "#   3. Create .env file in repo root: IPUMS_API_KEY=your_key\n",
    "#   4. Make sure .env is in .gitignore (it should be)\n",
    "# ============================================================\n",
    "\n",
    "IPUMS_API_KEY = os.environ.get(\"IPUMS_API_KEY\")\n",
    "\n",
    "if not IPUMS_API_KEY:\n",
    "    raise ValueError(\n",
    "        \"IPUMS_API_KEY not found!\\n\"\n",
    "        \"Create a .env file in the repo root with:\\n\"\n",
    "        \"IPUMS_API_KEY=your_key_here\\n\\n\"\n",
    "        \"See API_KEY_SETUP_GUIDE.md for full instructions.\"\n",
    "    )\n",
    "\n",
    "ipums = IpumsApiClient(IPUMS_API_KEY)\n",
    "print(f\"API client initialized (key: {IPUMS_API_KEY[:8]}...)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will request 14 tables × 3 election years\n",
      "States: ['Michigan', 'North Carolina', 'Pennsylvania']\n",
      "Download directory: c:\\Users\\Antoni\\OneDrive\\Pulpit\\CuBoulder\\2 sem\\Data Mining CSCI 5502\\project\\Data-Mining-Project-Group-1\\notebooks\\data\\nhgis_raw\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PROJECT CONSTANTS\n",
    "# ============================================================\n",
    "\n",
    "# Download directory for extract files\n",
    "DOWNLOAD_DIR = Path(\"data/nhgis_raw\")\n",
    "DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Output directory for processed data\n",
    "OUTPUT_DIR = Path(\"data/nhgis_processed\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Geographic extent codes (state FIPS + \"0\")\n",
    "STATE_EXTENTS = [\"260\", \"370\", \"420\"]  # MI, NC, PA\n",
    "\n",
    "STATE_FIPS = {\n",
    "    \"26\": \"Michigan\",\n",
    "    \"37\": \"North Carolina\",\n",
    "    \"42\": \"Pennsylvania\",\n",
    "}\n",
    "\n",
    "# ACS 5-Year datasets aligned with election years\n",
    "ELECTION_DATASETS = {\n",
    "    2016: \"2012_2016_ACS5a\",\n",
    "    2020: \"2016_2020_ACS5a\",\n",
    "    2024: \"2020_2024_ACS5a\",\n",
    "}\n",
    "\n",
    "# Backup: some detailed tables may only be in 'b' variants\n",
    "ELECTION_DATASETS_B = {\n",
    "    2016: \"2012_2016_ACS5b\",\n",
    "    2020: \"2016_2020_ACS5b\",\n",
    "    2024: \"2020_2024_ACS5b\",\n",
    "}\n",
    "\n",
    "# Core ACS data tables we want\n",
    "CORE_TABLES = [\n",
    "    \"B01003\",  # Total Population\n",
    "    \"B01002\",  # Median Age by Sex\n",
    "    \"B02001\",  # Race\n",
    "    \"B03002\",  # Hispanic/Latino Origin by Race\n",
    "    \"B15003\",  # Educational Attainment (25+)\n",
    "    \"B19013\",  # Median Household Income\n",
    "    \"B19001\",  # Household Income (brackets)\n",
    "    \"B17001\",  # Poverty Status\n",
    "    \"B23025\",  # Employment Status\n",
    "    \"B25077\",  # Median Home Value\n",
    "    \"B25003\",  # Tenure (Own vs. Rent)\n",
    "    \"B25064\",  # Median Gross Rent\n",
    "    \"B08301\",  # Means of Transportation to Work\n",
    "    \"B11001\",  # Household Type\n",
    "]\n",
    "\n",
    "print(f\"Will request {len(CORE_TABLES)} tables × {len(ELECTION_DATASETS)} election years\")\n",
    "print(f\"States: {list(STATE_FIPS.values())}\")\n",
    "print(f\"Download directory: {DOWNLOAD_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Explore Metadata — Verify Table Availability\n",
    "\n",
    "Before submitting extracts, we verify that our target tables exist in each dataset and that county-level data is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 2020_2024_ACS5a metadata...\n",
      "\n",
      "Description: 5-Year Data [2020-2024, Block Groups & Larger Areas]\n",
      "Number of data tables: 416\n",
      "\n",
      "Geographic levels available:\n",
      "  - nation: Nation (extent selection: False)\n",
      "  - region: Region (extent selection: False)\n",
      "  - division: Division (extent selection: False)\n",
      "  - state: State (extent selection: True)\n",
      "  - state_260: American Indian Area/Alaska Native Area/Hawaiian Home Land--State (extent selection: True)\n",
      "  - state_290: American Indian Area/Alaska Native Area/Hawaiian Home Land--Tribal Subdivision/Remainder--State (extent selection: True)\n",
      "  - state_311: Metropolitan Statistical Area/Micropolitan Statistical Area--State (extent selection: True)\n",
      "  - state_315: Metropolitan Statistical Area/Micropolitan Statistical Area--Metropolitan Division--State (extent selection: True)\n",
      "  - state_331: Combined Statistical Area--State (extent selection: True)\n",
      "  - state_333: Combined Statistical Area--Metropolitan Statistical Area/Micropolitan Statistical Area--State (extent selection: True)\n",
      "  - state_410: Urban Area--State (extent selection: True)\n",
      "  - county: State--County (extent selection: True)\n",
      "  - county_155: State--Place--County (extent selection: True)\n",
      "  - county_510_119: State--Congressional District (2025-2027, 119th Congress)--County (extent selection: True)\n",
      "  - county_612: State--State Legislative District (Upper Chamber)--County (extent selection: True)\n",
      "  - county_622: State--State Legislative District (Lower Chamber)--County (extent selection: True)\n",
      "  - county_322: State--Metropolitan Statistical Area/Micropolitan Statistical Area--County (extent selection: True)\n",
      "  - county_324: State--Metropolitan Statistical Area/Micropolitan Statistical Area--Metropolitan Division--County (extent selection: True)\n",
      "  - county_270: American Indian Area/Alaska Native Area/Hawaiian Home Land--State--County (extent selection: True)\n",
      "  - county_313: Metropolitan Statistical Area/Micropolitan Statistical Area--State--County (extent selection: True)\n",
      "  - county_316: Metropolitan Statistical Area/Micropolitan Statistical Area--Metropolitan Division--State--County (extent selection: True)\n",
      "  - county_430: Urban Area--State--County (extent selection: True)\n",
      "  - tract: State--County--Census Tract (extent selection: True)\n",
      "  - blck_grp: State--County--Census Tract--Block Group (extent selection: True)\n",
      "  - cty_sub: State--County--County Subdivision (extent selection: True)\n",
      "  - submcd: State--County--County Subdivision--Subminor Civil Division (extent selection: True)\n",
      "  - place: State--Place (extent selection: True)\n",
      "  - place_070: State--County--County Subdivision--Place/Remainder (extent selection: True)\n",
      "  - place_172: State--Consolidated City--Place within Consolidated City (extent selection: True)\n",
      "  - place_321: State--Metropolitan Statistical Area/Micropolitan Statistical Area--Principal City (extent selection: True)\n",
      "  - place_269: American Indian Area/Alaska Native Area/Hawaiian Home Land--State--Place/Remainder (extent selection: True)\n",
      "  - place_312: Metropolitan Statistical Area/Micropolitan Statistical Area--State--Principal City (extent selection: True)\n",
      "  - c_city: State--Consolidated City (extent selection: True)\n",
      "  - cd119th: State--Congressional District (2025-2027, 119th Congress) (extent selection: True)\n",
      "  - stleg_up: State--State Legislative District (Upper Chamber) (extent selection: True)\n",
      "  - stleg_lo: State--State Legislative District (Lower Chamber) (extent selection: True)\n",
      "  - sd_elm: State--School District (Elementary)/Remainder (extent selection: True)\n",
      "  - sd_sec: State--School District (Secondary)/Remainder (extent selection: True)\n",
      "  - sd_uni: State--School District (Unified)/Remainder (extent selection: True)\n",
      "  - puma: State--Public Use Microdata Area (extent selection: True)\n",
      "  - anrc: Alaska Native Regional Corporation (extent selection: False)\n",
      "  - aianhh: American Indian Area/Alaska Native Area/Hawaiian Home Land (extent selection: False)\n",
      "  - aianhh_280: State--American Indian Area/Alaska Native Area/Hawaiian Home Land (extent selection: True)\n",
      "  - aianhh_550_119: State--Congressional District (2025-2027, 119th Congress)--American Indian Area/Alaska Native Area/Hawaiian Home Land (extent selection: True)\n",
      "  - res_only: American Indian Area/Alaska Native Area (Reservation or Statistical Entity Only) (extent selection: False)\n",
      "  - res_only_283: State--American Indian Area/Alaska Native Area (Reservation or Statistical Entity Only) (extent selection: True)\n",
      "  - trust: American Indian Area (Off-Reservation Trust Land Only)/Hawaiian Home Land (extent selection: False)\n",
      "  - trust_286: State--American Indian Area (Off-Reservation Trust Land Only)/Hawaiian Home Land (extent selection: True)\n",
      "  - trbl_sub: American Indian Area/Alaska Native Area/Hawaiian Home Land--Tribal Subdivision/Remainder (extent selection: False)\n",
      "  - trbl_ct: American Indian Area/Alaska Native Area/Hawaiian Home Land--Tribal Census Tract (extent selection: False)\n",
      "  - trbl_ct_291: American Indian Area/Alaska Native Area (Reservation or Statistical Entity Only)--Tribal Census Tract (extent selection: False)\n",
      "  - trbl_ct_292: American Indian Area (Off-Reservation Trust Land Only)/Hawaiian Home Land--Tribal Census Tract (extent selection: False)\n",
      "  - trbl_bg: American Indian Area/Alaska Native Area/Hawaiian Home Land--Tribal Census Tract--Tribal Block Group (extent selection: False)\n",
      "  - trbl_bg_293: American Indian Area/Alaska Native Area (Reservation or Statistical Entity Only)--Tribal Census Tract--Tribal Block Group (extent selection: False)\n",
      "  - trbl_bg_294: American Indian Area (Off-Reservation Trust Land Only)/Hawaiian Home Land--Tribal Census Tract--Tribal Block Group (extent selection: False)\n",
      "  - cbsa: Metropolitan Statistical Area/Micropolitan Statistical Area (extent selection: False)\n",
      "  - cbsa_332: Combined Statistical Area--Metropolitan Statistical Area/Micropolitan Statistical Area (extent selection: False)\n",
      "  - cbsa_320: State--Metropolitan Statistical Area/Micropolitan Statistical Area (extent selection: True)\n",
      "  - cbsa_34101: State--Combined Statistical Area--Metropolitan Statistical Area/Micropolitan Statistical Area (extent selection: True)\n",
      "  - metdiv: Metropolitan Statistical Area/Micropolitan Statistical Area--Metropolitan Division (extent selection: False)\n",
      "  - metdiv_323: State--Metropolitan Statistical Area/Micropolitan Statistical Area--Metropolitan Division (extent selection: True)\n",
      "  - csa: Combined Statistical Area (extent selection: False)\n",
      "  - csa_340: State--Combined Statistical Area (extent selection: True)\n",
      "  - urb_area: Urban Area (extent selection: False)\n",
      "  - zcta: 5-Digit ZIP Code Tabulation Area (extent selection: False)\n"
     ]
    }
   ],
   "source": [
    "def check_dataset_metadata(dataset_name):\n",
    "    \"\"\"\n",
    "    Retrieve metadata for a single NHGIS dataset.\n",
    "    Returns the metadata object with data_tables, geog_levels, geographic_instances.\n",
    "    \"\"\"\n",
    "    ds_meta = NhgisDatasetMetadata(dataset_name)\n",
    "    ipums.get_metadata(ds_meta)\n",
    "    return ds_meta\n",
    "\n",
    "\n",
    "# Check the 2020-2024 dataset as our reference\n",
    "print(\"Checking 2020_2024_ACS5a metadata...\")\n",
    "ds_2024 = check_dataset_metadata(\"2020_2024_ACS5a\")\n",
    "\n",
    "print(f\"\\nDescription: {ds_2024.description}\")\n",
    "print(f\"Number of data tables: {len(ds_2024.data_tables)}\")\n",
    "print(f\"\\nGeographic levels available:\")\n",
    "for level in ds_2024.geog_levels:\n",
    "    print(f\"  - {level['name']}: {level['description']} (extent selection: {level['hasGeogExtentSelection']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TABLE AVAILABILITY CHECK\n",
      "============================================================\n",
      "\n",
      "--- 2016 election → 2012_2016_ACS5a ---\n",
      "  Found: 13/14 tables\n",
      "  ⚠ Missing from 'a' variant: ['B17001']\n",
      "  ✓ Found in '2012_2016_ACS5b': ['B17001']\n",
      "\n",
      "--- 2020 election → 2016_2020_ACS5a ---\n",
      "  Found: 13/14 tables\n",
      "  ⚠ Missing from 'a' variant: ['B17001']\n",
      "  ✓ Found in '2016_2020_ACS5b': ['B17001']\n",
      "\n",
      "--- 2024 election → 2020_2024_ACS5a ---\n",
      "  Found: 13/14 tables\n",
      "  ⚠ Missing from 'a' variant: ['B17001']\n",
      "  ✓ Found in '2020_2024_ACS5b': ['B17001']\n"
     ]
    }
   ],
   "source": [
    "def verify_tables_in_dataset(dataset_name, target_tables):\n",
    "    \"\"\"\n",
    "    Check which of our target tables are available in a given dataset.\n",
    "    Returns (found, missing) tuple of lists.\n",
    "    \"\"\"\n",
    "    ds_meta = check_dataset_metadata(dataset_name)\n",
    "    available = {t[\"name\"] for t in ds_meta.data_tables}\n",
    "    found = [t for t in target_tables if t in available]\n",
    "    missing = [t for t in target_tables if t not in available]\n",
    "    return found, missing\n",
    "\n",
    "\n",
    "# Verify all tables across all election-year datasets\n",
    "print(\"=\" * 60)\n",
    "print(\"TABLE AVAILABILITY CHECK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "tables_by_dataset = {}\n",
    "\n",
    "for year, ds_name in ELECTION_DATASETS.items():\n",
    "    print(f\"\\n--- {year} election → {ds_name} ---\")\n",
    "    found, missing = verify_tables_in_dataset(ds_name, CORE_TABLES)\n",
    "    tables_by_dataset[year] = {\"dataset\": ds_name, \"found\": found, \"missing\": missing}\n",
    "    print(f\"  Found: {len(found)}/{len(CORE_TABLES)} tables\")\n",
    "    if missing:\n",
    "        print(f\"  ⚠ Missing from 'a' variant: {missing}\")\n",
    "        # Check 'b' variant for missing tables\n",
    "        ds_b = ELECTION_DATASETS_B[year]\n",
    "        found_b, still_missing = verify_tables_in_dataset(ds_b, missing)\n",
    "        if found_b:\n",
    "            print(f\"  ✓ Found in '{ds_b}': {found_b}\")\n",
    "            tables_by_dataset[year][\"found_in_b\"] = found_b\n",
    "            tables_by_dataset[year][\"b_dataset\"] = ds_b\n",
    "        if still_missing:\n",
    "            print(f\"  ✗ Not found in either variant: {still_missing}\")\n",
    "    else:\n",
    "        print(f\"  ✓ All tables available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting B02001 (Race) from 2020_2024_ACS5a:\n",
      "==================================================\n",
      "Table: Race\n",
      "Universe: Total population\n",
      "NHGIS Code: AUO7\n",
      "\n",
      "Variables (10):\n",
      "  AUO7001: Total\n",
      "  AUO7002: White alone\n",
      "  AUO7003: Black or African American alone\n",
      "  AUO7004: American Indian and Alaska Native alone\n",
      "  AUO7005: Asian alone\n",
      "  AUO7006: Native Hawaiian and Other Pacific Islander alone\n",
      "  AUO7007: Some Other Race alone\n",
      "  AUO7008: Two or More Races\n",
      "  AUO7009: Two or More Races: Two races including Some Other Race\n",
      "  AUO7010: Two or More Races: Two races excluding Some Other Race, and three or more races\n"
     ]
    }
   ],
   "source": [
    "# Examine a specific data table's variables (example: B02001 - Race)\n",
    "print(\"Inspecting B02001 (Race) from 2020_2024_ACS5a:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "table_meta = NhgisDataTableMetadata(name=\"B02001\", dataset_name=\"2020_2024_ACS5a\")\n",
    "ipums.get_metadata(table_meta)\n",
    "\n",
    "print(f\"Table: {table_meta.description}\")\n",
    "print(f\"Universe: {table_meta.universe}\")\n",
    "print(f\"NHGIS Code: {table_meta.nhgis_code}\")\n",
    "print(f\"\\nVariables ({len(table_meta.variables)}):\")\n",
    "for var in table_meta.variables:\n",
    "    print(f\"  {var['nhgisCode']}: {var['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Table: B19013\n",
      "  Found in ACS5a\n",
      "  Description: Median Household Income in the Past 12 Months (in 2024 Inflation-Adjusted Dollars)\n",
      "  Universe: Households\n",
      "  Variables: 1\n",
      "\n",
      "==================================================\n",
      "Table: B15003\n",
      "  Found in ACS5a\n",
      "  Description: Educational Attainment for the Population 25 Years and Over\n",
      "  Universe: Population 25 years and over\n",
      "  Variables: 25\n",
      "\n",
      "==================================================\n",
      "Table: B17001\n",
      "  Not in ACS5a, checking ACS5b...\n",
      "  Found in ACS5b\n",
      "  Description: Poverty Status in the Past 12 Months by Sex by Age\n",
      "  Variables: 59\n"
     ]
    }
   ],
   "source": [
    "# Quick inspection of a few more key tables\n",
    "for tbl_name in [\"B19013\", \"B15003\", \"B17001\"]:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Table: {tbl_name}\")\n",
    "    # Try in ACS5a first\n",
    "    try:\n",
    "        tbl = NhgisDataTableMetadata(name=tbl_name, dataset_name=\"2020_2024_ACS5a\")\n",
    "        ipums.get_metadata(tbl)\n",
    "        print(f\"  Found in ACS5a\")\n",
    "        print(f\"  Description: {tbl.description}\")\n",
    "        print(f\"  Universe: {tbl.universe}\")\n",
    "        print(f\"  Variables: {len(tbl.variables)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Not in ACS5a, checking ACS5b...\")\n",
    "        try:\n",
    "            tbl = NhgisDataTableMetadata(name=tbl_name, dataset_name=\"2020_2024_ACS5b\")\n",
    "            ipums.get_metadata(tbl)\n",
    "            print(f\"  Found in ACS5b\")\n",
    "            print(f\"  Description: {tbl.description}\")\n",
    "            print(f\"  Variables: {len(tbl.variables)}\")\n",
    "        except Exception as e2:\n",
    "            print(f\"  ERROR: {e2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Define & Submit Extract Requests\n",
    "\n",
    "We create one extract per election year. Each extract pulls all target tables at the county level, restricted to PA, MI, and NC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built extract for 2016: <ipumspy.api.extract.AggregateDataExtract object at 0x0000024051ABE660>\n",
      "Built extract for 2020: <ipumspy.api.extract.AggregateDataExtract object at 0x0000024051B70F50>\n",
      "Built extract for 2024: <ipumspy.api.extract.AggregateDataExtract object at 0x0000024051B702D0>\n"
     ]
    }
   ],
   "source": [
    "def build_extract_for_year(election_year, tables_info):\n",
    "    \"\"\"\n",
    "    Build an AggregateDataExtract for a single election year.\n",
    "    Handles the case where some tables are in 'a' and some in 'b' variants.\n",
    "    \"\"\"\n",
    "    info = tables_info[election_year]\n",
    "    datasets = []\n",
    "\n",
    "    # Primary dataset ('a' variant)\n",
    "    if info[\"found\"]:\n",
    "        datasets.append(\n",
    "            NhgisDataset(\n",
    "                name=info[\"dataset\"],\n",
    "                data_tables=info[\"found\"],\n",
    "                geog_levels=[\"county\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Secondary dataset ('b' variant) for tables not in 'a'\n",
    "    if info.get(\"found_in_b\"):\n",
    "        datasets.append(\n",
    "            NhgisDataset(\n",
    "                name=info[\"b_dataset\"],\n",
    "                data_tables=info[\"found_in_b\"],\n",
    "                geog_levels=[\"county\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    extract = AggregateDataExtract(\n",
    "        collection=\"nhgis\",\n",
    "        description=f\"Swing State Demographics - {election_year} Election (ACS 5yr)\",\n",
    "        datasets=datasets,\n",
    "        geographic_extents=STATE_EXTENTS,  # MI, NC, PA only\n",
    "    )\n",
    "\n",
    "    return extract\n",
    "\n",
    "\n",
    "# Build extracts for all three election years\n",
    "extracts = {}\n",
    "for year in ELECTION_DATASETS:\n",
    "    extracts[year] = build_extract_for_year(year, tables_by_dataset)\n",
    "    print(f\"Built extract for {year}: {extracts[year]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save extract definitions to JSON for reproducibility\n# NOTE: Run this AFTER cell-15 (submit) — requires submitted extracts\nEXTRACT_DEFS_DIR = Path(\"data/extract_definitions\")\nEXTRACT_DEFS_DIR.mkdir(parents=True, exist_ok=True)\n\nfor year, ext in submitted_extracts.items():\n    filepath = EXTRACT_DEFS_DIR / f\"nhgis_extract_{year}.json\"\n    save_extract_as_json(ext, filepath)\n    print(f\"Saved extract definition: {filepath}\")\n\nprint(\"\\nExtract definitions saved. Share these with teammates for reproducibility.\")"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting extract for 2016...\n",
      "  → Extract #10 submitted (status: queued)\n",
      "Submitting extract for 2020...\n",
      "  → Extract #11 submitted (status: queued)\n",
      "Submitting extract for 2024...\n",
      "  → Extract #12 submitted (status: queued)\n",
      "\n",
      "✓ All extracts submitted. Waiting for processing...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SUBMIT EXTRACTS TO IPUMS\n",
    "# ============================================================\n",
    "# This sends the requests to IPUMS servers for processing.\n",
    "# Each extract typically processes in 30 seconds to 5 minutes.\n",
    "# ============================================================\n",
    "\n",
    "submitted_extracts = {}\n",
    "\n",
    "for year, ext in extracts.items():\n",
    "    print(f\"Submitting extract for {year}...\")\n",
    "    ipums.submit_extract(ext)\n",
    "    print(f\"  → Extract #{ext.extract_id} submitted (status: queued)\")\n",
    "    submitted_extracts[year] = ext\n",
    "\n",
    "print(\"\\n✓ All extracts submitted. Waiting for processing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Waiting for 2016 extract (#1)...\n",
      "  → Completed! Downloading...\n",
      "  → Downloaded to data\\nhgis_raw\n",
      "\n",
      "Waiting for 2020 extract (#2)...\n",
      "  → Completed! Downloading...\n",
      "  → Downloaded to data\\nhgis_raw\n",
      "\n",
      "Waiting for 2024 extract (#3)...\n",
      "  → Completed! Downloading...\n",
      "  → Downloaded to data\\nhgis_raw\n",
      "\n",
      "==================================================\n",
      "✓ ALL EXTRACTS DOWNLOADED\n",
      "==================================================\n",
      "  nhgis0001_csv.zip (176.6 KB)\n",
      "  nhgis0002_csv.zip (178.0 KB)\n",
      "  nhgis0003_csv.zip (181.4 KB)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# WAIT FOR COMPLETION & DOWNLOAD\n",
    "# ============================================================\n",
    "\n",
    "for year, ext in submitted_extracts.items():\n",
    "    print(f\"\\nWaiting for {year} extract (#{ext.extract_id})...\")\n",
    "    ipums.wait_for_extract(ext, timeout=600)  # 10 min timeout\n",
    "    print(f\"  → Completed! Downloading...\")\n",
    "\n",
    "    ipums.download_extract(ext, download_dir=DOWNLOAD_DIR)\n",
    "    print(f\"  → Downloaded to {DOWNLOAD_DIR}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"✓ ALL EXTRACTS DOWNLOADED\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Show downloaded files\n",
    "for f in sorted(DOWNLOAD_DIR.glob(\"*.zip\")):\n",
    "    print(f\"  {f.name} ({f.stat().st_size / 1024:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Load & Parse Downloaded Data\n",
    "\n",
    "NHGIS delivers aggregate data as CSV files inside ZIP archives. Each dataset/table combination produces a separate CSV. We'll unpack them and load into pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading: nhgis0001_csv.zip\n",
      "  Found 2 CSV files in nhgis0001_csv.zip\n",
      "    nhgis0001_csv/nhgis0001_ds226_20165_county.csv: 250 rows × 158 cols\n",
      "    nhgis0001_csv/nhgis0001_ds225_20165_county.csv: 250 rows × 282 cols\n",
      "\n",
      "Loading: nhgis0002_csv.zip\n",
      "  Found 2 CSV files in nhgis0002_csv.zip\n",
      "    nhgis0002_csv/nhgis0002_ds249_20205_county.csv: 250 rows × 282 cols\n",
      "    nhgis0002_csv/nhgis0002_ds250_20205_county.csv: 250 rows × 158 cols\n",
      "\n",
      "Loading: nhgis0003_csv.zip\n",
      "  Found 2 CSV files in nhgis0003_csv.zip\n",
      "    nhgis0003_csv/nhgis0003_ds272_20245_county.csv: 250 rows × 280 cols\n",
      "    nhgis0003_csv/nhgis0003_ds273_20245_county.csv: 250 rows × 156 cols\n"
     ]
    }
   ],
   "source": [
    "def load_nhgis_csvs_from_zip(zip_path):\n",
    "    \"\"\"\n",
    "    Load all CSV files from an NHGIS extract ZIP.\n",
    "    Returns a dict of {filename: DataFrame}.\n",
    "    Skips codebook .txt files.\n",
    "    \"\"\"\n",
    "    dfs = {}\n",
    "    with ZipFile(zip_path) as z:\n",
    "        csv_files = [n for n in z.namelist() if n.endswith(\".csv\")]\n",
    "        print(f\"  Found {len(csv_files)} CSV files in {zip_path.name}\")\n",
    "        for csv_name in csv_files:\n",
    "            with z.open(csv_name) as f:\n",
    "                df = pd.read_csv(f, encoding=\"latin-1\", low_memory=False)\n",
    "                dfs[csv_name] = df\n",
    "                print(f\"    {csv_name}: {df.shape[0]} rows × {df.shape[1]} cols\")\n",
    "    return dfs\n",
    "\n",
    "\n",
    "# Load all downloaded extracts\n",
    "all_data = {}\n",
    "for zip_file in sorted(DOWNLOAD_DIR.glob(\"*.zip\")):\n",
    "    if \"_csv\" in zip_file.name:  # Data files (not shape files)\n",
    "        print(f\"\\nLoading: {zip_file.name}\")\n",
    "        all_data[zip_file.name] = load_nhgis_csvs_from_zip(zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample file: nhgis0001_csv/nhgis0001_ds226_20165_county.csv\n",
      "Shape: (250, 158)\n",
      "\n",
      "Column names (first 30):\n",
      "  GISJOIN\n",
      "  YEAR\n",
      "  STUSAB\n",
      "  REGIONA\n",
      "  DIVISIONA\n",
      "  STATE\n",
      "  STATEA\n",
      "  COUNTY\n",
      "  COUNTYA\n",
      "  COUSUBA\n",
      "  PLACEA\n",
      "  TRACTA\n",
      "  CONCITA\n",
      "  AIANHHA\n",
      "  RES_ONLYA\n",
      "  TRUSTA\n",
      "  AIHHTLI\n",
      "  AITSCEA\n",
      "  ANRCA\n",
      "  CBSAA\n",
      "  CSAA\n",
      "  METDIVA\n",
      "  NECTAA\n",
      "  CNECTAA\n",
      "  NECTADIVA\n",
      "  UAA\n",
      "  CDCURRA\n",
      "  SLDUA\n",
      "  SLDLA\n",
      "  ZCTA5A\n",
      "\n",
      "First 3 rows (identifying columns):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GISJOIN</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>STUSAB</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATEA</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>COUNTYA</th>\n",
       "      <th>NAME_E</th>\n",
       "      <th>NAME_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G2600010</td>\n",
       "      <td>2012-2016</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>26</td>\n",
       "      <td>Alcona County</td>\n",
       "      <td>1</td>\n",
       "      <td>Alcona County, Michigan</td>\n",
       "      <td>Alcona County, Michigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G2600030</td>\n",
       "      <td>2012-2016</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>26</td>\n",
       "      <td>Alger County</td>\n",
       "      <td>3</td>\n",
       "      <td>Alger County, Michigan</td>\n",
       "      <td>Alger County, Michigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G2600050</td>\n",
       "      <td>2012-2016</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>26</td>\n",
       "      <td>Allegan County</td>\n",
       "      <td>5</td>\n",
       "      <td>Allegan County, Michigan</td>\n",
       "      <td>Allegan County, Michigan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GISJOIN       YEAR STUSAB     STATE  STATEA          COUNTY  COUNTYA  \\\n",
       "0  G2600010  2012-2016     MI  Michigan      26   Alcona County        1   \n",
       "1  G2600030  2012-2016     MI  Michigan      26    Alger County        3   \n",
       "2  G2600050  2012-2016     MI  Michigan      26  Allegan County        5   \n",
       "\n",
       "                     NAME_E                    NAME_M  \n",
       "0   Alcona County, Michigan   Alcona County, Michigan  \n",
       "1    Alger County, Michigan    Alger County, Michigan  \n",
       "2  Allegan County, Michigan  Allegan County, Michigan  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examine the structure of one loaded file\n",
    "# NHGIS CSVs contain identifying columns (GISJOIN, STATE, COUNTY, etc.) plus data columns\n",
    "\n",
    "# Get the first dataframe from the first zip\n",
    "if all_data:\n",
    "    first_zip = list(all_data.keys())[0]\n",
    "    first_csv = list(all_data[first_zip].keys())[0]\n",
    "    sample_df = all_data[first_zip][first_csv]\n",
    "\n",
    "    print(f\"Sample file: {first_csv}\")\n",
    "    print(f\"Shape: {sample_df.shape}\")\n",
    "    print(f\"\\nColumn names (first 30):\")\n",
    "    for col in sample_df.columns[:30]:\n",
    "        print(f\"  {col}\")\n",
    "\n",
    "    print(f\"\\nFirst 3 rows (identifying columns):\")\n",
    "    id_cols = [c for c in sample_df.columns if c in [\n",
    "        \"GISJOIN\", \"YEAR\", \"STATE\", \"STATEA\", \"COUNTY\", \"COUNTYA\",\n",
    "        \"STUSAB\", \"NAME_E\", \"NAME_M\"\n",
    "    ]]\n",
    "    display(sample_df[id_cols].head(3))\n",
    "else:\n",
    "    print(\"No data loaded yet. Run the extract/download cells above first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Filter to Target States & Validate Coverage\n",
    "\n",
    "Verify we have data for all counties in PA, MI, and NC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Validating: nhgis0001_csv.zip\n",
      "\n",
      "  File: nhgis0001_csv/nhgis0001_ds226_20165_county.csv\n",
      "  ✓ Michigan: 83/83 counties\n",
      "  ✓ North Carolina: 100/100 counties\n",
      "  ✓ Pennsylvania: 67/67 counties\n",
      "\n",
      "  File: nhgis0001_csv/nhgis0001_ds225_20165_county.csv\n",
      "  ✓ Michigan: 83/83 counties\n",
      "  ✓ North Carolina: 100/100 counties\n",
      "  ✓ Pennsylvania: 67/67 counties\n",
      "\n",
      "==================================================\n",
      "Validating: nhgis0002_csv.zip\n",
      "\n",
      "  File: nhgis0002_csv/nhgis0002_ds249_20205_county.csv\n",
      "  ✓ Michigan: 83/83 counties\n",
      "  ✓ North Carolina: 100/100 counties\n",
      "  ✓ Pennsylvania: 67/67 counties\n",
      "\n",
      "  File: nhgis0002_csv/nhgis0002_ds250_20205_county.csv\n",
      "  ✓ Michigan: 83/83 counties\n",
      "  ✓ North Carolina: 100/100 counties\n",
      "  ✓ Pennsylvania: 67/67 counties\n",
      "\n",
      "==================================================\n",
      "Validating: nhgis0003_csv.zip\n",
      "\n",
      "  File: nhgis0003_csv/nhgis0003_ds272_20245_county.csv\n",
      "  ✓ Michigan: 83/83 counties\n",
      "  ✓ North Carolina: 100/100 counties\n",
      "  ✓ Pennsylvania: 67/67 counties\n",
      "\n",
      "  File: nhgis0003_csv/nhgis0003_ds273_20245_county.csv\n",
      "  ✓ Michigan: 83/83 counties\n",
      "  ✓ North Carolina: 100/100 counties\n",
      "  ✓ Pennsylvania: 67/67 counties\n"
     ]
    }
   ],
   "source": [
    "# Expected county counts\n",
    "EXPECTED_COUNTIES = {\n",
    "    \"Michigan\": 83,\n",
    "    \"North Carolina\": 100,\n",
    "    \"Pennsylvania\": 67,\n",
    "}\n",
    "\n",
    "\n",
    "def validate_county_coverage(df, state_fips_col=\"STATEA\"):\n",
    "    \"\"\"\n",
    "    Check that we have the expected number of counties per state.\n",
    "    STATEA column in NHGIS contains the state FIPS code (as string).\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for fips, state_name in STATE_FIPS.items():\n",
    "        state_data = df[df[state_fips_col].astype(str).str.strip() == fips]\n",
    "        n_counties = state_data[\"COUNTYA\"].nunique() if \"COUNTYA\" in df.columns else len(state_data)\n",
    "        expected = EXPECTED_COUNTIES[state_name]\n",
    "        status = \"✓\" if n_counties == expected else \"⚠\"\n",
    "        results[state_name] = {\"found\": n_counties, \"expected\": expected, \"status\": status}\n",
    "        print(f\"  {status} {state_name}: {n_counties}/{expected} counties\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# Validate each loaded dataset\n",
    "if all_data:\n",
    "    for zip_name, csvs in all_data.items():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Validating: {zip_name}\")\n",
    "        for csv_name, df in csvs.items():\n",
    "            print(f\"\\n  File: {csv_name}\")\n",
    "            if \"STATEA\" in df.columns:\n",
    "                validate_county_coverage(df)\n",
    "            else:\n",
    "                print(\"  (No STATEA column — checking available ID columns)\")\n",
    "                print(f\"  Columns: {[c for c in df.columns if not c.startswith(('A', 'B', 'C'))]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Process & Structure the Data\n",
    "\n",
    "Merge all tables for each election year into a single county-level DataFrame with meaningful column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged nhgis0001_csv.zip: (250, 400)\n",
      "  ID columns: ['GISJOIN', 'YEAR', 'STUSAB', 'STATE', 'STATEA', 'COUNTY', 'COUNTYA']\n",
      "  Data columns: 393\n",
      "Merged nhgis0002_csv.zip: (250, 400)\n",
      "  ID columns: ['GISJOIN', 'YEAR', 'STUSAB', 'STATE', 'STATEA', 'COUNTY', 'COUNTYA']\n",
      "  Data columns: 393\n",
      "Merged nhgis0003_csv.zip: (250, 398)\n",
      "  ID columns: ['GISJOIN', 'YEAR', 'STUSAB', 'STATE', 'STATEA', 'COUNTY', 'COUNTYA']\n",
      "  Data columns: 391\n"
     ]
    }
   ],
   "source": [
    "# NHGIS identifying columns that we want to keep as our key\n",
    "ID_COLUMNS = [\n",
    "    \"GISJOIN\",    # Unique geographic identifier (stable across datasets)\n",
    "    \"YEAR\",       # Data year\n",
    "    \"STUSAB\",     # State abbreviation (e.g., PA, MI, NC)\n",
    "    \"STATE\",      # State name\n",
    "    \"STATEA\",     # State FIPS code\n",
    "    \"COUNTY\",     # County name\n",
    "    \"COUNTYA\",    # County FIPS code\n",
    "]\n",
    "\n",
    "\n",
    "def merge_nhgis_csvs(csv_dict):\n",
    "    \"\"\"\n",
    "    Merge multiple NHGIS CSV DataFrames from a single extract\n",
    "    on their shared GISJOIN key.\n",
    "    \"\"\"\n",
    "    dfs = list(csv_dict.values())\n",
    "    if not dfs:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Start with the first DataFrame\n",
    "    merged = dfs[0].copy()\n",
    "\n",
    "    # Merge subsequent DataFrames on GISJOIN\n",
    "    for df in dfs[1:]:\n",
    "        # Identify data columns (not ID columns)\n",
    "        data_cols = [c for c in df.columns if c not in merged.columns]\n",
    "        merge_cols = [\"GISJOIN\"] + data_cols\n",
    "        merged = merged.merge(df[merge_cols], on=\"GISJOIN\", how=\"outer\")\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "# Process each extract into a clean DataFrame\n",
    "# (This section becomes active after data is downloaded)\n",
    "if all_data:\n",
    "    for zip_name, csvs in all_data.items():\n",
    "        merged = merge_nhgis_csvs(csvs)\n",
    "        print(f\"Merged {zip_name}: {merged.shape}\")\n",
    "        # Show available ID columns\n",
    "        avail_ids = [c for c in ID_COLUMNS if c in merged.columns]\n",
    "        print(f\"  ID columns: {avail_ids}\")\n",
    "        print(f\"  Data columns: {merged.shape[1] - len(avail_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Build Unified County Demographics Panel\n",
    "\n",
    "Create the final structured dataset: one row per county per election year, with key demographic variables derived from the raw NHGIS tables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NHGIS code mappings loaded for 2016, 2020, 2024.\n",
      "  Example: B01003 (Total Population)\n",
      "    2016: column = AF2LE001\n",
      "    2020: column = AMPVE001\n",
      "    2024: column = AUO6E001\n"
     ]
    }
   ],
   "source": [
    "# Year-specific NHGIS code mappings \n",
    "# These were extracted from the codebook TXT files inside each ZIP.\n",
    "# Each ACS edition uses DIFFERENT 4-letter prefixes for the same Census tables.\n",
    "\n",
    "NHGIS_CODES = {\n",
    "    2016: {  # nhgis0001 — ACS 2012-2016\n",
    "        \"B01003\": \"AF2L\",   # Total Population\n",
    "        \"B01002\": \"AF2B\",   # Median Age by Sex\n",
    "        \"B02001\": \"AF2M\",   # Race\n",
    "        \"B03002\": \"AF2U\",   # Hispanic/Latino Origin by Race\n",
    "        \"B08301\": \"AF3B\",   # Means of Transportation to Work\n",
    "        \"B11001\": \"AF3J\",   # Household Type\n",
    "        \"B15003\": \"AF4O\",   # Educational Attainment (25+)\n",
    "        \"B17001\": \"AGI6\",   # Poverty Status (from 'b' variant)\n",
    "        \"B19001\": \"AF48\",   # Household Income Distribution\n",
    "        \"B19013\": \"AF49\",   # Median Household Income\n",
    "        \"B23025\": \"AF67\",   # Employment Status\n",
    "        \"B25003\": \"AF7P\",   # Tenure (Owner/Renter)\n",
    "        \"B25064\": \"AF89\",   # Median Gross Rent\n",
    "        \"B25077\": \"AF9L\",   # Median Home Value\n",
    "    },\n",
    "    2020: {  # nhgis0002 — ACS 2016-2020\n",
    "        \"B01003\": \"AMPV\",\n",
    "        \"B01002\": \"AMPL\",\n",
    "        \"B02001\": \"AMPW\",\n",
    "        \"B03002\": \"AMP3\",\n",
    "        \"B08301\": \"AMQK\",\n",
    "        \"B11001\": \"AMQS\",\n",
    "        \"B15003\": \"AMRZ\",\n",
    "        \"B17001\": \"AM63\",   # from 'b' variant\n",
    "        \"B19001\": \"AMR7\",\n",
    "        \"B19013\": \"AMR8\",\n",
    "        \"B23025\": \"AMT9\",\n",
    "        \"B25003\": \"AMUF\",\n",
    "        \"B25064\": \"AMVZ\",\n",
    "        \"B25077\": \"AMWB\",\n",
    "    },\n",
    "    2024: {  # nhgis0003 — ACS 2020-2024\n",
    "        \"B01003\": \"AUO6\",\n",
    "        \"B01002\": \"AUOW\",\n",
    "        \"B02001\": \"AUO7\",\n",
    "        \"B03002\": \"AUPF\",\n",
    "        \"B08301\": \"AUPW\",\n",
    "        \"B11001\": \"AUP1\",\n",
    "        \"B15003\": \"AUQ8\",\n",
    "        \"B17001\": \"AU77\",   # from 'b' variant\n",
    "        \"B19001\": \"AURT\",\n",
    "        \"B19013\": \"AURU\",\n",
    "        \"B23025\": \"AUTW\",\n",
    "        \"B25003\": \"AUUE\",\n",
    "        \"B25064\": \"AUWG\",\n",
    "        \"B25077\": \"AUWS\",\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"NHGIS code mappings loaded for 2016, 2020, 2024.\")\n",
    "print(f\"  Example: B01003 (Total Population)\")\n",
    "for yr in [2016, 2020, 2024]:\n",
    "    pfx = NHGIS_CODES[yr][\"B01003\"]\n",
    "    print(f\"    {yr}: column = {pfx}E001\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_demographics() function defined.\n",
      "Derived variables (30):\n",
      "  • total_population\n",
      "  • median_age\n",
      "  • pct_white\n",
      "  • pct_black\n",
      "  • pct_asian\n",
      "  • pct_two_or_more_races\n",
      "  • pct_hispanic\n",
      "  • pct_non_hispanic_white\n",
      "  • pct_hs_or_higher\n",
      "  • pct_bachelors_plus\n",
      "  • pct_no_hs_diploma\n",
      "  • pct_below_poverty\n",
      "  • median_household_income\n",
      "  • pct_income_under_25k\n",
      "  • pct_income_50k_100k\n",
      "  • pct_income_over_100k\n",
      "  • unemployment_rate\n",
      "  • pct_owner_occupied\n",
      "  • pct_renter_occupied\n",
      "  • median_gross_rent\n",
      "  • median_home_value\n",
      "  • pct_drive_alone\n",
      "  • pct_carpool\n",
      "  • pct_public_transit\n",
      "  • pct_work_from_home\n",
      "  • pct_family_households\n",
      "  • pct_married_couple\n",
      "  • pct_living_alone\n"
     ]
    }
   ],
   "source": [
    "# Build derived variables for one year \n",
    "\n",
    "def col(codes, table, var_num):\n",
    "    \"\"\"Helper: build NHGIS column name like 'AF2LE001' from table code and variable number.\"\"\"\n",
    "    prefix = codes[table]\n",
    "    return f\"{prefix}E{var_num:03d}\"\n",
    "\n",
    "\n",
    "def build_demographics(df, election_year, codes):\n",
    "    \"\"\"\n",
    "    Extract and compute ~30 derived demographic variables from a merged NHGIS DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        df: merged DataFrame (a + b variants joined on GISJOIN) for one election year\n",
    "        election_year: 2016, 2020, or 2024\n",
    "        codes: dict mapping Census table codes to NHGIS prefixes for this year\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with one row per county, standardized column names\n",
    "    \"\"\"\n",
    "    out = pd.DataFrame()\n",
    "    \n",
    "    # ── Identifiers ──\n",
    "    out[\"county_fips\"] = df[\"STATEA\"].astype(str).str.zfill(2) + df[\"COUNTYA\"].astype(str).str.zfill(3)\n",
    "    out[\"gisjoin\"] = df[\"GISJOIN\"]\n",
    "    out[\"state\"] = df[\"STUSAB\"]\n",
    "    out[\"county_name\"] = df[\"COUNTY\"]\n",
    "    out[\"election_year\"] = election_year\n",
    "    \n",
    "    # ── B01003: Total Population ──\n",
    "    out[\"total_population\"] = df[col(codes, \"B01003\", 1)]\n",
    "    \n",
    "    # ── B01002: Median Age ──\n",
    "    out[\"median_age\"] = df[col(codes, \"B01002\", 1)]\n",
    "    \n",
    "    # ── B02001: Race (percentages) ──\n",
    "    race_total = df[col(codes, \"B02001\", 1)]\n",
    "    out[\"pct_white\"] = df[col(codes, \"B02001\", 2)] / race_total * 100\n",
    "    out[\"pct_black\"] = df[col(codes, \"B02001\", 3)] / race_total * 100\n",
    "    out[\"pct_asian\"] = df[col(codes, \"B02001\", 5)] / race_total * 100\n",
    "    out[\"pct_two_or_more_races\"] = df[col(codes, \"B02001\", 8)] / race_total * 100\n",
    "    \n",
    "    # ── B03002: Hispanic/Latino Origin ──\n",
    "    hisp_total = df[col(codes, \"B03002\", 1)]\n",
    "    out[\"pct_hispanic\"] = df[col(codes, \"B03002\", 12)] / hisp_total * 100\n",
    "    out[\"pct_non_hispanic_white\"] = df[col(codes, \"B03002\", 3)] / hisp_total * 100\n",
    "    \n",
    "    # ── B15003: Educational Attainment (25+) ──\n",
    "    edu_total = df[col(codes, \"B15003\", 1)]\n",
    "    # HS or higher = Regular HS diploma (17) + GED (18) + Some college (19,20) + Associate (21) + BA (22) + MA (23) + Professional (24) + Doctorate (25)\n",
    "    hs_plus = sum(df[col(codes, \"B15003\", i)] for i in range(17, 26))\n",
    "    out[\"pct_hs_or_higher\"] = hs_plus / edu_total * 100\n",
    "    # Bachelor's or higher = BA (22) + MA (23) + Professional (24) + Doctorate (25)\n",
    "    ba_plus = sum(df[col(codes, \"B15003\", i)] for i in range(22, 26))\n",
    "    out[\"pct_bachelors_plus\"] = ba_plus / edu_total * 100\n",
    "    # No HS diploma = vars 2-16 (no schooling through 12th grade no diploma)\n",
    "    no_hs = sum(df[col(codes, \"B15003\", i)] for i in range(2, 17))\n",
    "    out[\"pct_no_hs_diploma\"] = no_hs / edu_total * 100\n",
    "    \n",
    "    # ── B17001: Poverty Status ──\n",
    "    poverty_total = df[col(codes, \"B17001\", 1)]\n",
    "    poverty_below = df[col(codes, \"B17001\", 2)]\n",
    "    out[\"pct_below_poverty\"] = poverty_below / poverty_total * 100\n",
    "    \n",
    "    # ── B19013: Median Household Income ──\n",
    "    out[\"median_household_income\"] = df[col(codes, \"B19013\", 1)]\n",
    "    \n",
    "    # ── B19001: Income Distribution (selected brackets) ──\n",
    "    inc_total = df[col(codes, \"B19001\", 1)]\n",
    "    # Low income: <$25k (vars 2-5)\n",
    "    low_inc = sum(df[col(codes, \"B19001\", i)] for i in range(2, 6))\n",
    "    out[\"pct_income_under_25k\"] = low_inc / inc_total * 100\n",
    "    # Middle income: $50k-$100k (vars 11-13)\n",
    "    mid_inc = sum(df[col(codes, \"B19001\", i)] for i in range(11, 14))\n",
    "    out[\"pct_income_50k_100k\"] = mid_inc / inc_total * 100\n",
    "    # High income: $100k+ (vars 14-17)\n",
    "    high_inc = sum(df[col(codes, \"B19001\", i)] for i in range(14, 18))\n",
    "    out[\"pct_income_over_100k\"] = high_inc / inc_total * 100\n",
    "    \n",
    "    # ── B23025: Employment Status ──\n",
    "    civilian_labor = df[col(codes, \"B23025\", 3)]\n",
    "    unemployed = df[col(codes, \"B23025\", 5)]\n",
    "    out[\"unemployment_rate\"] = unemployed / civilian_labor * 100\n",
    "    \n",
    "    # ── B25003: Tenure (Owner vs Renter) ──\n",
    "    tenure_total = df[col(codes, \"B25003\", 1)]\n",
    "    out[\"pct_owner_occupied\"] = df[col(codes, \"B25003\", 2)] / tenure_total * 100\n",
    "    out[\"pct_renter_occupied\"] = df[col(codes, \"B25003\", 3)] / tenure_total * 100\n",
    "    \n",
    "    # ── B25064: Median Gross Rent ──\n",
    "    out[\"median_gross_rent\"] = df[col(codes, \"B25064\", 1)]\n",
    "    \n",
    "    # ── B25077: Median Home Value ──\n",
    "    out[\"median_home_value\"] = df[col(codes, \"B25077\", 1)]\n",
    "    \n",
    "    # ── B08301: Means of Transportation to Work ──\n",
    "    transport_total = df[col(codes, \"B08301\", 1)]\n",
    "    out[\"pct_drive_alone\"] = df[col(codes, \"B08301\", 3)] / transport_total * 100\n",
    "    out[\"pct_carpool\"] = df[col(codes, \"B08301\", 4)] / transport_total * 100\n",
    "    out[\"pct_public_transit\"] = df[col(codes, \"B08301\", 10)] / transport_total * 100\n",
    "    out[\"pct_work_from_home\"] = df[col(codes, \"B08301\", 21)] / transport_total * 100\n",
    "    \n",
    "    # ── B11001: Household Type ──\n",
    "    hh_total = df[col(codes, \"B11001\", 1)]\n",
    "    out[\"pct_family_households\"] = df[col(codes, \"B11001\", 2)] / hh_total * 100\n",
    "    out[\"pct_married_couple\"] = df[col(codes, \"B11001\", 3)] / hh_total * 100\n",
    "    out[\"pct_living_alone\"] = df[col(codes, \"B11001\", 8)] / hh_total * 100\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "print(\"build_demographics() function defined.\")\n",
    "print(\"Derived variables (30):\")\n",
    "demo_vars = [\n",
    "    \"total_population\", \"median_age\",\n",
    "    \"pct_white\", \"pct_black\", \"pct_asian\", \"pct_two_or_more_races\",\n",
    "    \"pct_hispanic\", \"pct_non_hispanic_white\",\n",
    "    \"pct_hs_or_higher\", \"pct_bachelors_plus\", \"pct_no_hs_diploma\",\n",
    "    \"pct_below_poverty\",\n",
    "    \"median_household_income\", \"pct_income_under_25k\", \"pct_income_50k_100k\", \"pct_income_over_100k\",\n",
    "    \"unemployment_rate\",\n",
    "    \"pct_owner_occupied\", \"pct_renter_occupied\",\n",
    "    \"median_gross_rent\", \"median_home_value\",\n",
    "    \"pct_drive_alone\", \"pct_carpool\", \"pct_public_transit\", \"pct_work_from_home\",\n",
    "    \"pct_family_households\", \"pct_married_couple\", \"pct_living_alone\",\n",
    "]\n",
    "for v in demo_vars:\n",
    "    print(f\"  • {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 2016 (nhgis0001_csv.zip)...\n",
      "  ✓ 250 counties, 33 variables\n",
      "\n",
      "Processing 2020 (nhgis0002_csv.zip)...\n",
      "  ✓ 250 counties, 33 variables\n",
      "\n",
      "Processing 2024 (nhgis0003_csv.zip)...\n",
      "  ✓ 250 counties, 33 variables\n",
      "\n",
      "==================================================\n",
      "UNIFIED PANEL: 750 rows × 33 columns\n",
      "  Counties per year: {2016: 250, 2020: 250, 2024: 250}\n",
      "  States: ['MI', 'NC', 'PA']\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_fips</th>\n",
       "      <th>gisjoin</th>\n",
       "      <th>state</th>\n",
       "      <th>county_name</th>\n",
       "      <th>election_year</th>\n",
       "      <th>total_population</th>\n",
       "      <th>median_age</th>\n",
       "      <th>pct_white</th>\n",
       "      <th>pct_black</th>\n",
       "      <th>pct_asian</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_renter_occupied</th>\n",
       "      <th>median_gross_rent</th>\n",
       "      <th>median_home_value</th>\n",
       "      <th>pct_drive_alone</th>\n",
       "      <th>pct_carpool</th>\n",
       "      <th>pct_public_transit</th>\n",
       "      <th>pct_work_from_home</th>\n",
       "      <th>pct_family_households</th>\n",
       "      <th>pct_married_couple</th>\n",
       "      <th>pct_living_alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26001</td>\n",
       "      <td>G2600010</td>\n",
       "      <td>MI</td>\n",
       "      <td>Alcona County</td>\n",
       "      <td>2016</td>\n",
       "      <td>10461</td>\n",
       "      <td>57.4</td>\n",
       "      <td>97.352070</td>\n",
       "      <td>0.248542</td>\n",
       "      <td>0.411051</td>\n",
       "      <td>...</td>\n",
       "      <td>11.582546</td>\n",
       "      <td>592</td>\n",
       "      <td>97500</td>\n",
       "      <td>82.127396</td>\n",
       "      <td>8.379716</td>\n",
       "      <td>0.216450</td>\n",
       "      <td>5.225727</td>\n",
       "      <td>62.718681</td>\n",
       "      <td>52.785039</td>\n",
       "      <td>33.259602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26003</td>\n",
       "      <td>G2600030</td>\n",
       "      <td>MI</td>\n",
       "      <td>Alger County</td>\n",
       "      <td>2016</td>\n",
       "      <td>9396</td>\n",
       "      <td>49.0</td>\n",
       "      <td>85.483184</td>\n",
       "      <td>7.322265</td>\n",
       "      <td>0.276713</td>\n",
       "      <td>...</td>\n",
       "      <td>13.574133</td>\n",
       "      <td>610</td>\n",
       "      <td>118500</td>\n",
       "      <td>72.304774</td>\n",
       "      <td>10.433133</td>\n",
       "      <td>1.802087</td>\n",
       "      <td>8.662662</td>\n",
       "      <td>64.608214</td>\n",
       "      <td>54.937373</td>\n",
       "      <td>31.255462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26005</td>\n",
       "      <td>G2600050</td>\n",
       "      <td>MI</td>\n",
       "      <td>Allegan County</td>\n",
       "      <td>2016</td>\n",
       "      <td>113666</td>\n",
       "      <td>40.0</td>\n",
       "      <td>94.399381</td>\n",
       "      <td>1.429627</td>\n",
       "      <td>0.653670</td>\n",
       "      <td>...</td>\n",
       "      <td>18.851700</td>\n",
       "      <td>757</td>\n",
       "      <td>144600</td>\n",
       "      <td>86.036905</td>\n",
       "      <td>7.493051</td>\n",
       "      <td>0.250926</td>\n",
       "      <td>3.972359</td>\n",
       "      <td>73.157232</td>\n",
       "      <td>60.170558</td>\n",
       "      <td>21.842412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26007</td>\n",
       "      <td>G2600070</td>\n",
       "      <td>MI</td>\n",
       "      <td>Alpena County</td>\n",
       "      <td>2016</td>\n",
       "      <td>28929</td>\n",
       "      <td>47.3</td>\n",
       "      <td>96.833627</td>\n",
       "      <td>0.594559</td>\n",
       "      <td>0.400982</td>\n",
       "      <td>...</td>\n",
       "      <td>23.109708</td>\n",
       "      <td>570</td>\n",
       "      <td>92700</td>\n",
       "      <td>82.642529</td>\n",
       "      <td>9.764089</td>\n",
       "      <td>0.614351</td>\n",
       "      <td>3.808978</td>\n",
       "      <td>62.991318</td>\n",
       "      <td>48.295185</td>\n",
       "      <td>31.681137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26009</td>\n",
       "      <td>G2600090</td>\n",
       "      <td>MI</td>\n",
       "      <td>Antrim County</td>\n",
       "      <td>2016</td>\n",
       "      <td>23215</td>\n",
       "      <td>50.0</td>\n",
       "      <td>95.899203</td>\n",
       "      <td>0.340297</td>\n",
       "      <td>0.267069</td>\n",
       "      <td>...</td>\n",
       "      <td>15.984148</td>\n",
       "      <td>699</td>\n",
       "      <td>145100</td>\n",
       "      <td>75.312067</td>\n",
       "      <td>13.389523</td>\n",
       "      <td>0.458765</td>\n",
       "      <td>7.841673</td>\n",
       "      <td>69.860787</td>\n",
       "      <td>58.449345</td>\n",
       "      <td>25.424246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  county_fips   gisjoin state     county_name  election_year  \\\n",
       "0       26001  G2600010    MI   Alcona County           2016   \n",
       "1       26003  G2600030    MI    Alger County           2016   \n",
       "2       26005  G2600050    MI  Allegan County           2016   \n",
       "3       26007  G2600070    MI   Alpena County           2016   \n",
       "4       26009  G2600090    MI   Antrim County           2016   \n",
       "\n",
       "   total_population  median_age  pct_white  pct_black  pct_asian  ...  \\\n",
       "0             10461        57.4  97.352070   0.248542   0.411051  ...   \n",
       "1              9396        49.0  85.483184   7.322265   0.276713  ...   \n",
       "2            113666        40.0  94.399381   1.429627   0.653670  ...   \n",
       "3             28929        47.3  96.833627   0.594559   0.400982  ...   \n",
       "4             23215        50.0  95.899203   0.340297   0.267069  ...   \n",
       "\n",
       "   pct_renter_occupied  median_gross_rent  median_home_value  pct_drive_alone  \\\n",
       "0            11.582546                592              97500        82.127396   \n",
       "1            13.574133                610             118500        72.304774   \n",
       "2            18.851700                757             144600        86.036905   \n",
       "3            23.109708                570              92700        82.642529   \n",
       "4            15.984148                699             145100        75.312067   \n",
       "\n",
       "   pct_carpool  pct_public_transit  pct_work_from_home  pct_family_households  \\\n",
       "0     8.379716            0.216450            5.225727              62.718681   \n",
       "1    10.433133            1.802087            8.662662              64.608214   \n",
       "2     7.493051            0.250926            3.972359              73.157232   \n",
       "3     9.764089            0.614351            3.808978              62.991318   \n",
       "4    13.389523            0.458765            7.841673              69.860787   \n",
       "\n",
       "   pct_married_couple  pct_living_alone  \n",
       "0           52.785039         33.259602  \n",
       "1           54.937373         31.255462  \n",
       "2           60.170558         21.842412  \n",
       "3           48.295185         31.681137  \n",
       "4           58.449345         25.424246  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build panel from all 3 years \n",
    "\n",
    "# 'merged_data' should be the dict from Section 5: {zip_name: merged_DataFrame}\n",
    "# Map zip names to election years\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Re-merge from all_data (Section 5 didn't save to a dict)\n",
    "def merge_csvs(csv_dict):\n",
    "    dfs = list(csv_dict.values())\n",
    "    merged = dfs[0].copy()\n",
    "    for df in dfs[1:]:\n",
    "        data_cols = [c for c in df.columns if c not in merged.columns]\n",
    "        merge_cols = [\"GISJOIN\"] + data_cols\n",
    "        merged = merged.merge(df[merge_cols], on=\"GISJOIN\", how=\"outer\")\n",
    "    return merged\n",
    "\n",
    "merged_data = {}\n",
    "for zip_name, csvs in all_data.items():\n",
    "    merged_data[zip_name] = merge_csvs(csvs)\n",
    "\n",
    "\n",
    "ZIP_TO_YEAR = {\n",
    "    \"nhgis0001_csv.zip\": 2016,\n",
    "    \"nhgis0002_csv.zip\": 2020,\n",
    "    \"nhgis0003_csv.zip\": 2024,\n",
    "}\n",
    "\n",
    "panels = []\n",
    "for zip_name, year in ZIP_TO_YEAR.items():\n",
    "    print(f\"\\nProcessing {year} ({zip_name})...\")\n",
    "    df = merged_data[zip_name]\n",
    "    codes = NHGIS_CODES[year]\n",
    "    \n",
    "    demo = build_demographics(df, year, codes)\n",
    "    panels.append(demo)\n",
    "    print(f\"  ✓ {len(demo)} counties, {len(demo.columns)} variables\")\n",
    "\n",
    "# Stack all years into one panel\n",
    "panel = pd.concat(panels, ignore_index=True)\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(f\"UNIFIED PANEL: {panel.shape[0]} rows × {panel.shape[1]} columns\")\n",
    "print(f\"  Counties per year: {panel.groupby('election_year')['county_fips'].count().to_dict()}\")\n",
    "print(f\"  States: {sorted(panel['state'].unique())}\")\n",
    "print(f\"{'=' * 50}\")\n",
    "\n",
    "panel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sanity Checks ===\n",
      "\n",
      "✓ No missing county FIPS codes\n",
      "✓ 750 rows (250 counties × 3 years)\n",
      "✓ County counts correct: MI=83, NC=100, PA=67 per year\n",
      "✓ All 22 percentage columns checked\n",
      "✓ All populations > 0\n",
      "\n",
      "=== Summary Statistics ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>election_year</th>\n",
       "      <th>total_population</th>\n",
       "      <th>median_age</th>\n",
       "      <th>pct_white</th>\n",
       "      <th>pct_black</th>\n",
       "      <th>pct_asian</th>\n",
       "      <th>pct_two_or_more_races</th>\n",
       "      <th>pct_hispanic</th>\n",
       "      <th>pct_non_hispanic_white</th>\n",
       "      <th>pct_hs_or_higher</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_renter_occupied</th>\n",
       "      <th>median_gross_rent</th>\n",
       "      <th>median_home_value</th>\n",
       "      <th>pct_drive_alone</th>\n",
       "      <th>pct_carpool</th>\n",
       "      <th>pct_public_transit</th>\n",
       "      <th>pct_work_from_home</th>\n",
       "      <th>pct_family_households</th>\n",
       "      <th>pct_married_couple</th>\n",
       "      <th>pct_living_alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>...</td>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "      <td>750.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2020.00</td>\n",
       "      <td>132821.64</td>\n",
       "      <td>43.60</td>\n",
       "      <td>81.47</td>\n",
       "      <td>10.48</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.79</td>\n",
       "      <td>5.61</td>\n",
       "      <td>79.02</td>\n",
       "      <td>88.76</td>\n",
       "      <td>...</td>\n",
       "      <td>25.94</td>\n",
       "      <td>816.60</td>\n",
       "      <td>167238.00</td>\n",
       "      <td>79.33</td>\n",
       "      <td>9.42</td>\n",
       "      <td>0.73</td>\n",
       "      <td>6.64</td>\n",
       "      <td>65.19</td>\n",
       "      <td>49.48</td>\n",
       "      <td>29.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.27</td>\n",
       "      <td>234273.18</td>\n",
       "      <td>5.28</td>\n",
       "      <td>16.16</td>\n",
       "      <td>13.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.48</td>\n",
       "      <td>4.44</td>\n",
       "      <td>16.72</td>\n",
       "      <td>4.41</td>\n",
       "      <td>...</td>\n",
       "      <td>7.55</td>\n",
       "      <td>202.20</td>\n",
       "      <td>71395.81</td>\n",
       "      <td>5.05</td>\n",
       "      <td>2.18</td>\n",
       "      <td>1.75</td>\n",
       "      <td>4.01</td>\n",
       "      <td>4.37</td>\n",
       "      <td>5.55</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2016.00</td>\n",
       "      <td>2102.00</td>\n",
       "      <td>26.40</td>\n",
       "      <td>24.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>23.25</td>\n",
       "      <td>72.05</td>\n",
       "      <td>...</td>\n",
       "      <td>8.38</td>\n",
       "      <td>431.00</td>\n",
       "      <td>68400.00</td>\n",
       "      <td>45.97</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>51.13</td>\n",
       "      <td>27.30</td>\n",
       "      <td>16.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2016.00</td>\n",
       "      <td>25611.25</td>\n",
       "      <td>40.60</td>\n",
       "      <td>73.86</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.98</td>\n",
       "      <td>2.17</td>\n",
       "      <td>69.95</td>\n",
       "      <td>86.35</td>\n",
       "      <td>...</td>\n",
       "      <td>20.91</td>\n",
       "      <td>677.25</td>\n",
       "      <td>116275.00</td>\n",
       "      <td>77.32</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3.93</td>\n",
       "      <td>62.72</td>\n",
       "      <td>46.16</td>\n",
       "      <td>26.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2020.00</td>\n",
       "      <td>54794.00</td>\n",
       "      <td>43.30</td>\n",
       "      <td>88.24</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.63</td>\n",
       "      <td>3.12</td>\n",
       "      <td>4.35</td>\n",
       "      <td>85.25</td>\n",
       "      <td>89.55</td>\n",
       "      <td>...</td>\n",
       "      <td>25.27</td>\n",
       "      <td>769.00</td>\n",
       "      <td>152350.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>9.19</td>\n",
       "      <td>0.34</td>\n",
       "      <td>5.51</td>\n",
       "      <td>65.42</td>\n",
       "      <td>50.03</td>\n",
       "      <td>29.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2024.00</td>\n",
       "      <td>137647.25</td>\n",
       "      <td>46.78</td>\n",
       "      <td>93.52</td>\n",
       "      <td>14.26</td>\n",
       "      <td>1.32</td>\n",
       "      <td>4.94</td>\n",
       "      <td>7.53</td>\n",
       "      <td>92.26</td>\n",
       "      <td>91.78</td>\n",
       "      <td>...</td>\n",
       "      <td>30.14</td>\n",
       "      <td>906.75</td>\n",
       "      <td>197975.00</td>\n",
       "      <td>82.60</td>\n",
       "      <td>10.47</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8.24</td>\n",
       "      <td>68.08</td>\n",
       "      <td>53.16</td>\n",
       "      <td>31.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024.00</td>\n",
       "      <td>1772259.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>99.22</td>\n",
       "      <td>62.04</td>\n",
       "      <td>9.23</td>\n",
       "      <td>15.29</td>\n",
       "      <td>27.98</td>\n",
       "      <td>97.68</td>\n",
       "      <td>97.12</td>\n",
       "      <td>...</td>\n",
       "      <td>48.55</td>\n",
       "      <td>1763.00</td>\n",
       "      <td>485600.00</td>\n",
       "      <td>90.15</td>\n",
       "      <td>25.40</td>\n",
       "      <td>25.71</td>\n",
       "      <td>29.06</td>\n",
       "      <td>81.37</td>\n",
       "      <td>65.56</td>\n",
       "      <td>40.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       election_year  total_population  median_age  pct_white  pct_black  \\\n",
       "count         750.00            750.00      750.00     750.00     750.00   \n",
       "mean         2020.00         132821.64       43.60      81.47      10.48   \n",
       "std             3.27         234273.18        5.28      16.16      13.61   \n",
       "min          2016.00           2102.00       26.40      24.17       0.00   \n",
       "25%          2016.00          25611.25       40.60      73.86       1.16   \n",
       "50%          2020.00          54794.00       43.30      88.24       3.94   \n",
       "75%          2024.00         137647.25       46.78      93.52      14.26   \n",
       "max          2024.00        1772259.00       60.00      99.22      62.04   \n",
       "\n",
       "       pct_asian  pct_two_or_more_races  pct_hispanic  pct_non_hispanic_white  \\\n",
       "count     750.00                 750.00        750.00                  750.00   \n",
       "mean        1.25                   3.79          5.61                   79.02   \n",
       "std         1.60                   2.48          4.44                   16.72   \n",
       "min         0.00                   0.02          0.10                   23.25   \n",
       "25%         0.42                   1.98          2.17                   69.95   \n",
       "50%         0.63                   3.12          4.35                   85.25   \n",
       "75%         1.32                   4.94          7.53                   92.26   \n",
       "max         9.23                  15.29         27.98                   97.68   \n",
       "\n",
       "       pct_hs_or_higher  ...  pct_renter_occupied  median_gross_rent  \\\n",
       "count            750.00  ...               750.00             750.00   \n",
       "mean              88.76  ...                25.94             816.60   \n",
       "std                4.41  ...                 7.55             202.20   \n",
       "min               72.05  ...                 8.38             431.00   \n",
       "25%               86.35  ...                20.91             677.25   \n",
       "50%               89.55  ...                25.27             769.00   \n",
       "75%               91.78  ...                30.14             906.75   \n",
       "max               97.12  ...                48.55            1763.00   \n",
       "\n",
       "       median_home_value  pct_drive_alone  pct_carpool  pct_public_transit  \\\n",
       "count             750.00           750.00       750.00              750.00   \n",
       "mean           167238.00            79.33         9.42                0.73   \n",
       "std             71395.81             5.05         2.18                1.75   \n",
       "min             68400.00            45.97         2.42                0.00   \n",
       "25%            116275.00            77.32         8.05                0.14   \n",
       "50%            152350.00            80.00         9.19                0.34   \n",
       "75%            197975.00            82.60        10.47                0.70   \n",
       "max            485600.00            90.15        25.40               25.71   \n",
       "\n",
       "       pct_work_from_home  pct_family_households  pct_married_couple  \\\n",
       "count              750.00                 750.00              750.00   \n",
       "mean                 6.64                  65.19               49.48   \n",
       "std                  4.01                   4.37                5.55   \n",
       "min                  0.80                  51.13               27.30   \n",
       "25%                  3.93                  62.72               46.16   \n",
       "50%                  5.51                  65.42               50.03   \n",
       "75%                  8.24                  68.08               53.16   \n",
       "max                 29.06                  81.37               65.56   \n",
       "\n",
       "       pct_living_alone  \n",
       "count            750.00  \n",
       "mean              29.19  \n",
       "std                3.66  \n",
       "min               16.64  \n",
       "25%               26.83  \n",
       "50%               29.18  \n",
       "75%               31.30  \n",
       "max               40.58  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick sanity checks \n",
    "\n",
    "print(\"=== Sanity Checks ===\\n\")\n",
    "\n",
    "# Check no missing county_fips\n",
    "assert panel[\"county_fips\"].notna().all(), \"Missing county FIPS codes!\"\n",
    "print(\"✓ No missing county FIPS codes\")\n",
    "\n",
    "# Check expected row count\n",
    "assert len(panel) == 750, f\"Expected 750 rows, got {len(panel)}\"\n",
    "print(\"✓ 750 rows (250 counties × 3 years)\")\n",
    "\n",
    "# Check county counts per state per year\n",
    "for yr in [2016, 2020, 2024]:\n",
    "    subset = panel[panel[\"election_year\"] == yr]\n",
    "    mi = (subset[\"state\"] == \"MI\").sum()\n",
    "    nc = (subset[\"state\"] == \"NC\").sum()\n",
    "    pa = (subset[\"state\"] == \"PA\").sum()\n",
    "    assert mi == 83 and nc == 100 and pa == 67, f\"County count mismatch in {yr}\"\n",
    "print(\"✓ County counts correct: MI=83, NC=100, PA=67 per year\")\n",
    "\n",
    "# Check percentage columns are in [0, 100]\n",
    "pct_cols = [c for c in panel.columns if c.startswith(\"pct_\")]\n",
    "for c in pct_cols:\n",
    "    vals = panel[c].dropna()\n",
    "    if vals.min() < -0.01 or vals.max() > 100.01:\n",
    "        print(f\"  ⚠ {c}: range [{vals.min():.2f}, {vals.max():.2f}]\")\n",
    "    else:\n",
    "        pass  # OK\n",
    "print(f\"✓ All {len(pct_cols)} percentage columns checked\")\n",
    "\n",
    "# Check population > 0\n",
    "assert (panel[\"total_population\"] > 0).all(), \"Zero-population counties found!\"\n",
    "print(\"✓ All populations > 0\")\n",
    "\n",
    "# Summary stats\n",
    "print(f\"\\n=== Summary Statistics ===\")\n",
    "panel.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Added land_area_sqmi and population_density\n",
      "  Missing area: 0\n",
      "  Density range: 3.9 – 11773.9 per sq mi\n",
      "\n",
      "✓ Panel exported to data\\county_demographics_panel.csv\n",
      "  Shape: (750, 35)\n",
      "  File size: 377.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Add Population Density & Export to CSV \n",
    "# Drop if re-running\n",
    "panel = panel.drop(columns=[\"land_area_sqmi\", \"population_density\"], errors=\"ignore\")\n",
    "# Download county land area from Census Gazetteer (per-state files: MI=26, NC=37, PA=42)\n",
    "import io, urllib.request\n",
    "\n",
    "gaz_frames = []\n",
    "for fips in [\"26\", \"37\", \"42\"]:\n",
    "    url = f\"https://www2.census.gov/geo/docs/maps-data/data/gazetteer/2024_Gazetteer/2024_gaz_counties_{fips}.txt\"\n",
    "    response = urllib.request.urlopen(url)\n",
    "    gaz_frames.append(pd.read_csv(io.BytesIO(response.read()), sep=\"\\t\", dtype={\"GEOID\": str}))\n",
    "\n",
    "gaz = pd.concat(gaz_frames, ignore_index=True)\n",
    "gaz = gaz[[\"GEOID\", \"ALAND_SQMI\"]].rename(columns={\"GEOID\": \"county_fips\", \"ALAND_SQMI\": \"land_area_sqmi\"})\n",
    "\n",
    "# Merge and compute density\n",
    "panel = panel.merge(gaz, on=\"county_fips\", how=\"left\")\n",
    "panel[\"population_density\"] = panel[\"total_population\"] / panel[\"land_area_sqmi\"]\n",
    "\n",
    "print(f\"✓ Added land_area_sqmi and population_density\")\n",
    "print(f\"  Missing area: {panel['land_area_sqmi'].isna().sum()}\")\n",
    "print(f\"  Density range: {panel['population_density'].min():.1f} – {panel['population_density'].max():.1f} per sq mi\")\n",
    "\n",
    "# Export\n",
    "OUTPUT_PATH = Path(\"data/county_demographics_panel.csv\")\n",
    "OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "panel.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"\\n✓ Panel exported to {OUTPUT_PATH}\")\n",
    "print(f\"  Shape: {panel.shape}\")\n",
    "print(f\"  File size: {OUTPUT_PATH.stat().st_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Appendix A: IPUMS NHGIS Citation\n",
    "\n",
    "Required citation for any use of NHGIS data:\n",
    "\n",
    "> Steven Manson, Jonathan Schroeder, David Van Riper, Katherine Knowles, Tracy Kugler, Finn Roberts, and Steven Ruggles. IPUMS National Historical Geographic Information System: Version 19.0 [dataset]. Minneapolis, MN: IPUMS. 2024. http://doi.org/10.18128/D050.V19.0\n",
    "\n",
    "## Appendix B: Reproducibility\n",
    "\n",
    "Extract definitions are saved as JSON files in `data/extract_definitions/`. Teammates can resubmit identical extracts by running:\n",
    "\n",
    "```python\n",
    "from ipumspy import define_extract_from_json, IpumsApiClient\n",
    "ext = define_extract_from_json(\"data/extract_definitions/nhgis_extract_2024.json\")\n",
    "ipums = IpumsApiClient(os.environ[\"IPUMS_API_KEY\"])\n",
    "ipums.submit_extract(ext)\n",
    "```\n",
    "\n",
    "## Appendix C: Additional Table Ideas\n",
    "\n",
    "If you want more differentiating variables, consider adding:\n",
    "\n",
    "| Table | Description | Why Useful |\n",
    "|---|---|---|\n",
    "| B08006 | Sex of Workers by Transportation to Work | Commuting patterns |\n",
    "| B16010 | Educational Attainment & Earnings | Income by education |\n",
    "| B25071 | Median Gross Rent as % of Income | Housing affordability |\n",
    "| B27001 | Health Insurance Coverage | Healthcare access |\n",
    "| B14007 | School Enrollment by Level | Education engagement |\n",
    "| B24011 | Occupation by Median Earnings | Economic structure |\n",
    "| B99021 | Allocation of Household Type | Data quality flag |\n",
    "| C24050 | Industry for Workers | Economic base |\n",
    "| B05001 | Nativity & Citizenship | Immigration |\n",
    "| B28002 | Internet Subscriptions | Digital access/rural proxy |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}